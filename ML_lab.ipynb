{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t- instant: record index\n",
    "\t- dteday : date\n",
    "\t- season : season (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "\t- yr : year (0: 2011, 1:2012)\n",
    "\t- mnth : month ( 1 to 12)\n",
    "\t- hr : hour (0 to 23)\n",
    "\t- holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "\t- weekday : day of the week\n",
    "\t- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "\t+ weathersit : \n",
    "\t\t- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "\t\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "\t\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "\t\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "\t- temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n",
    "\t- atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n",
    "\t- hum: Normalized humidity. The values are divided to 100 (max)\n",
    "\t- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "\t- casual: count of casual users\n",
    "\t- registered: count of registered users\n",
    "\t- cnt: count of total rental bikes including both casual and registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('~/Desktop/py/data/day.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "features = [\n",
    "    'instant', 'season', 'yr', 'mnth', 'holiday', 'weekday',\n",
    "    'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed'\n",
    "]\n",
    "\n",
    "target = 'cnt'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (584, 12) y_train shape:  (584,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape,'y_train shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Preprocessing - DataFrameMapper is acting up so using https://stackoverflow.com/questions/37685412/avoid-scaling-binary-columns-in-sci-kit-learn-standsardscaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "continuous_cols = [\n",
    "    'instant', 'season', 'mnth', 'weekday',\n",
    "    'weathersit', 'temp', 'atemp', 'hum', 'windspeed'\n",
    "]\n",
    "\n",
    "binary_cols = ['yr', 'holiday', 'workingday']\n",
    "\n",
    "mapper = DataFrameMapper(\n",
    "    [(continuous_col, StandardScaler()) for continuous_col in continuous_cols] +\n",
    "    [(binary_cols, None) for binary_col in binary_cols]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('mapper', mapper)\n",
    "])\n",
    "\n",
    "pipeline.fit_transform(X_train)\n",
    "X_train.describe()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class StandardScalerSelect(BaseEstimator, TransformerMixin): \n",
    "    '''\n",
    "    This class enables us to choose which columns to StandardScale.\n",
    "    Only the variables referred to with cont_vars_index are scaled.\n",
    "    '''\n",
    "    def __init__(self, bin_vars_index, cont_vars_index, copy=True, with_mean=True, with_std=True):\n",
    "        self.scaler = StandardScaler(copy, with_mean, with_std)\n",
    "        self.bin_vars_index = bin_vars_index\n",
    "        self.cont_vars_index = cont_vars_index\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[:, self.cont_vars_index], y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        X_tail = self.scaler.transform(X[:, self.cont_vars_index], y, copy)\n",
    "        return np.concatenate((X[:, self.bin_vars_index], X_tail), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\econsw\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:675: DeprecationWarning: The parameter y on transform() is deprecated since 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "cont_vars = [\n",
    "    'instant', 'season', 'mnth', 'weekday',\n",
    "    'weathersit', 'temp', 'atemp', 'hum', 'windspeed'\n",
    "]\n",
    "\n",
    "bin_vars = ['yr', 'holiday', 'workingday']\n",
    "\n",
    "cont_vars_index = [X.columns.get_loc(c) for c in X.columns if c in cont_vars]\n",
    "\n",
    "bin_vars_index = [X.columns.get_loc(c) for c in X.columns if c in bin_vars]\n",
    "\n",
    "# Unsure about what order to do the scaling and polynomial expansion in\n",
    "\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)),\n",
    "    ('scaler', StandardScalerSelect(bin_vars_index=bin_vars_index, cont_vars_index=cont_vars_index)),\n",
    "])\n",
    "\n",
    "X_train_new = model.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure what to do from here. Adding a model to the end of pipeline? Ran into some issues trying to combine the custom scaler and LassoCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
