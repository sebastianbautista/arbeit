{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaBi ML fitting - Random Forest - Total rides\n",
    "\n",
    "In this notebook I use RandomForestRegressor to fit on our training data, 1/1/2013 to 9/8/2017, score the model using 5-fold cross-validation, then predict on our test data, 9/9/2017 to 4/30/2018.\n",
    "\n",
    "Dependent variable = total DC to DC CaBi rides.\n",
    "\n",
    "TODO: Run without the full/empty duration data? Simultaneity problems with rides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data load, shaping, and split\n",
    "\n",
    "* Read in data from AWS\n",
    "  * Check for high pairwise correlation\n",
    "* Encode time variable (day_of_year) as cyclical\n",
    "* Split into Xtrain, Xtest, ytrain, ytest based on date\n",
    "  * Specify feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from AWS\n",
    "\n",
    "from util_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "set_env_path()\n",
    "conn, cur = aws_connect()\n",
    "\n",
    "# fullquery contains pretty much everything\n",
    "\n",
    "fullquery = \"\"\"\n",
    "SELECT \n",
    "EXTRACT(DOY FROM date) as day_of_year,\n",
    "date,\n",
    "year,\n",
    "quarter,\n",
    "month,\n",
    "day_of_week,\n",
    "daylight_hours,\n",
    "apparenttemperaturehigh,\n",
    "apparenttemperaturehightime,\n",
    "apparenttemperaturelow,\n",
    "apparenttemperaturelowtime,\n",
    "precipintensitymaxtime,\n",
    "sunrisetime,\n",
    "sunsettime,\n",
    "cloudcover,\n",
    "dewpoint,\n",
    "humidity,\n",
    "precipaccumulation,\n",
    "precipintensitymax,\n",
    "precipprobability,\n",
    "rain,\n",
    "snow,\n",
    "visibility,\n",
    "windspeed,\n",
    "us_holiday,\n",
    "nats_single,\n",
    "nats_double,\n",
    "nats_attendance,\n",
    "dc_bike_event,\n",
    "dc_pop,\n",
    "cabi_bikes_avail,\n",
    "cabi_stations_alx,\n",
    "cabi_stations_arl,\n",
    "cabi_stations_ffx,\n",
    "cabi_stations_mcn,\n",
    "cabi_stations_mcs,\n",
    "cabi_stations_wdc,\n",
    "cabi_docks_alx,\n",
    "cabi_docks_arl,\n",
    "cabi_docks_ffx,\n",
    "cabi_docks_mcn,\n",
    "cabi_docks_mcs,\n",
    "cabi_docks_wdc,\n",
    "cabi_stations_tot,\n",
    "cabi_docks_tot,\n",
    "cabi_dur_empty_wdc,\n",
    "cabi_dur_full_wdc,\n",
    "cabi_dur_empty_arl,\n",
    "cabi_dur_full_arl,\n",
    "cabi_dur_full_alx,\n",
    "cabi_dur_empty_alx,\n",
    "cabi_dur_empty_mcs,\n",
    "cabi_dur_full_mcs,\n",
    "cabi_dur_full_mcn,\n",
    "cabi_dur_empty_mcn,\n",
    "cabi_dur_full_ffx,\n",
    "cabi_dur_empty_ffx,\n",
    "cabi_dur_empty_tot,\n",
    "cabi_dur_full_tot,\n",
    "cabi_active_members_day_key,\n",
    "cabi_active_members_monthly,\n",
    "cabi_active_members_annual,\n",
    "cabi_trips_wdc_to_wdc,\n",
    "cabi_trips_wdc_to_wdc_casual\n",
    "from final_db\"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "EXTRACT(DOY FROM date) as day_of_year,\n",
    "date,\n",
    "year,\n",
    "quarter,\n",
    "month,\n",
    "day_of_week,\n",
    "daylight_hours,\n",
    "apparenttemperaturehigh,\n",
    "apparenttemperaturehightime,\n",
    "apparenttemperaturelow,\n",
    "apparenttemperaturelowtime,\n",
    "precipintensitymaxtime,\n",
    "sunrisetime,\n",
    "sunsettime,\n",
    "cloudcover,\n",
    "dewpoint,\n",
    "humidity,\n",
    "precipaccumulation,\n",
    "precipintensitymax,\n",
    "precipprobability,\n",
    "rain,\n",
    "snow,\n",
    "visibility,\n",
    "windspeed,\n",
    "us_holiday,\n",
    "nats_single,\n",
    "nats_double,\n",
    "nats_attendance,\n",
    "dc_bike_event,\n",
    "dc_pop,\n",
    "cabi_bikes_avail,\n",
    "cabi_stations_alx,\n",
    "cabi_stations_arl,\n",
    "cabi_stations_ffx,\n",
    "cabi_stations_mcn,\n",
    "cabi_stations_mcs,\n",
    "cabi_stations_wdc,\n",
    "cabi_docks_alx,\n",
    "cabi_docks_arl,\n",
    "cabi_docks_ffx,\n",
    "cabi_docks_mcn,\n",
    "cabi_docks_mcs,\n",
    "cabi_docks_wdc,\n",
    "cabi_stations_tot,\n",
    "cabi_docks_tot,\n",
    "cabi_active_members_day_key,\n",
    "cabi_active_members_monthly,\n",
    "cabi_active_members_annual,\n",
    "cabi_trips_wdc_to_wdc,\n",
    "cabi_trips_wdc_to_wdc_casual\n",
    "from final_db\"\"\"\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "\n",
    "# Setting date to index for easier splitting\n",
    "df.set_index(df.date, drop=True, inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "print(\"We have {} instances and {} features\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[.5]).round(3).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_highly_correlated(df, features, threshold=0.75):\n",
    "    \"\"\" \n",
    "    Prints highly correlated feature pairs in df. Threshold set at 0.75 by default.\n",
    "    Selects pairs where abs(r) is above the threshold, puts them in a DataFrame,\n",
    "    making sure to avoid duplication, then sorts by abs(r) and prints.\n",
    "    \"\"\"\n",
    "    corr_df = df[features].corr()\n",
    "    correlated_features = np.where(np.abs(corr_df) > threshold)\n",
    "    correlated_features = [(corr_df.iloc[x,y], x, y) for x, y in zip(*correlated_features) if x != y and x < y]\n",
    "    s_corr_list = sorted(correlated_features, key=lambda x: -abs(x[0]))\n",
    "    print(\"There are {} feature pairs with pairwise correlation above {}\".format(len(s_corr_list), threshold))\n",
    "    for v, i, j in s_corr_list:\n",
    "        cols = df[features].columns\n",
    "        print(\"{} and {} = {:0.3f}\".format(corr_df.index[i], corr_df.columns[j], v))\n",
    "        \n",
    "print_highly_correlated(df, df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode day of year as cyclical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sin_day_of_year'] = np.sin(2*np.pi*df.day_of_year/365)\n",
    "df['cos_day_of_year'] = np.cos(2*np.pi*df.day_of_year/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df.sample(100).plot.scatter('sin_day_of_year','cos_day_of_year').set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split into Xtrain, Xtest, ytrain, ytest based on date\n",
    "  * Training dates = 2013-01-01 to 2017-09-08\n",
    "  * Test dates = 2017-09-09 to 2018-04-30\n",
    "    * Coincides with dockless pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc['2013-01-01':'2017-09-08']\n",
    "test = df.loc['2017-09-09':'2018-04-30']\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "tr = train.shape[0]\n",
    "te = test.shape[0]\n",
    "trpct = tr/(tr+te)\n",
    "tepct = te/(tr+te)\n",
    "\n",
    "print(\"{:0.3f} percent of the data is in the training set and {:0.3f} percent is in the test set\".format(trpct, tepct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to keep and drop for X and y\n",
    "drop_cols = ['date']\n",
    "y_cols = ['cabi_trips_wdc_to_wdc', 'cabi_trips_wdc_to_wdc_casual']\n",
    "\n",
    "feature_cols = [col for col in df.columns if (col not in y_cols) & (col not in drop_cols)]\n",
    "\n",
    "# X y split\n",
    "Xtrain = train[feature_cols]\n",
    "\n",
    "# Our target variable here is all DC to DC trips\n",
    "ytrain = train[y_cols[0]]\n",
    "Xtest = test[feature_cols]\n",
    "ytest = test[y_cols[0]]\n",
    "print(Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Hyperparameter Tuning\n",
    "\n",
    "* Scoring functions\n",
    "* RandomizedSearchCV\n",
    "* GridSearchCV\n",
    "  * Compare GridSearch and RandomizedSearch scores and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def score_model(model):\n",
    "    \"\"\" \n",
    "    Fits a model using the training set, predicts using the test set, and then calculates \n",
    "    and reports goodness of fit metrics.\n",
    "    \"\"\"\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    yhat = model.predict(Xtest)\n",
    "    r2 = r2_score(ytest, yhat)\n",
    "    me = mse(ytest, yhat)\n",
    "    print(\"Results from {}: \\nr2={:0.3f} \\nMSE={:0.3f}\".format(model, r2, me))\n",
    "\n",
    "def cv_score(model, n_splits=5):\n",
    "    \"\"\"\n",
    "    Evaluates a model by 5-fold cross-validation and prints mean and 2*stdev of scores.\n",
    "    Shuffles before cross-validation but sets random_state=7 for reproducibility.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=7)\n",
    "    scores = cross_val_score(model, Xtrain, ytrain, cv=kf, \n",
    "                             scoring=None,\n",
    "                             n_jobs=-1, verbose=3)\n",
    "    print(scores)\n",
    "    print(\"R^2: {:0.3f} (+/- {:0.3f})\".format(scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV\n",
    "\n",
    "We need to find appropriate values for our hyperparameters.\n",
    "\n",
    "We can start by using RandomizedSearchCV to cast a wide net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_distributions = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altogether, there are 10 * 2 * 12 * 3 * 4 * 2 = 5760 combinations.\n",
    "\n",
    "We randomly sample 100 times per fold for a total of 500 fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 5-fold cross-validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "ran_search = RandomizedSearchCV(estimator=rf, \n",
    "                               param_distributions=param_distributions,\n",
    "                               scoring=None,\n",
    "                               n_iter=100, cv=cv, verbose=3, \n",
    "                               random_state=7, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "ran_search.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in seeing if there's any improvement between the untuned default RF model and our new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = ran_search.best_estimator_\n",
    "\n",
    "print(\"Cross-validation score for base RF\")\n",
    "cv_score(rf)\n",
    "\n",
    "print(\"\\nCross-validation score for RF tuned by RandomizedSearchCV\")\n",
    "cv_score(rf_random)\n",
    "print()\n",
    "\n",
    "# What parameters are used?\n",
    "pprint(ran_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV\n",
    "\n",
    "Slight increase in performance with the parameters suggested by RandomizedSearchCV.\n",
    "\n",
    "Next, we use GridSearchCV which iterates over all of the possible combinations instead of randomly sampling.\n",
    "\n",
    "*Note: User input required in the next section to create the GridSearch parameter grid based on RandomizedSearch results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# Create the parameter grid based on the results of the random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [50, 60, 70, 80, 90, None],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': [500, 1000, 1400, 1600]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           scoring=None,\n",
    "                           cv=cv, n_jobs=-1, verbose=3)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this new model compare to the RandomizedSearchCV model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = grid_search.best_estimator_\n",
    "\n",
    "print(\"Cross-validation score for untuned RF\")\n",
    "cv_score(rf)\n",
    "print(\"\\nCross-validation score for RF tuned by RandomizedSearchCV\")\n",
    "cv_score(rf_random)\n",
    "print(\"\\nCross-validation score for RF tuned by GridSearchCV\")\n",
    "cv_score(rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do parameters differ between specifications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandomizedSearchCV params:\")\n",
    "pprint(ran_search.best_params_)\n",
    "print(\"\\nGridSearchCV params:\")\n",
    "pprint(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf_best.feature_importances_,\n",
    "                                   index = Xtrain.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "# Print 20 most important features\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Fitting\n",
    "\n",
    "* Fit on training data and predict on test data\n",
    "  * Check residuals and prediction error graphs (yellowbrick)\n",
    "* Plot predicted values vs actuals (yhat, ytest) \n",
    "* Calculate and plot residuals (ytest - yhat) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our model perform on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do our residuals look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "resplot = ResidualsPlot(rf_best)\n",
    "\n",
    "resplot.fit(Xtrain, ytrain)\n",
    "resplot.score(Xtest, ytest)\n",
    "g = resplot.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our prediction error look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "prederr = PredictionError(rf_best)\n",
    "\n",
    "prederr.fit(Xtrain, ytrain)\n",
    "prederr.score(Xtrain, ytrain)\n",
    "g = prederr.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pull out our fitted values (yhat) and actuals (ytest) to see how they compare.\n",
    "\n",
    "We also calculate our residuals by subtracting our fitted values from the actuals.\n",
    "\n",
    "TODO: \n",
    "* See if the plot looks okay as is\n",
    "  * Might be best to put residuals in another chart because of scale\n",
    "  * May want to replace t with actual date - pull out from index?\n",
    "* See if seaborn.tsplot offers better options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best.fit(Xtrain, ytrain)\n",
    "\n",
    "yhat = model.predict(Xtest)\n",
    "resid = ytest - yhat\n",
    "\n",
    "data = pd.DataFrame({'t': range(1, len(yhat) + 1), \n",
    "                     'ytest': ytest, \n",
    "                     'yhat': yhat,\n",
    "                     'resid': resid})\n",
    "\n",
    "plt.plot('t', 'ytest', data=data, marker='', color='blue', linewidth=2, label='actual')\n",
    "plt.plot('t', 'yhat', data=data, marker='', color='blue', linewidth=2, linestyle='dashed', label='predicted')\n",
    "plt.plot('t', 'resid', data=data, marker='', color='orange', linewidth=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = (time.perf_counter() - start_time)/60\n",
    "print(\"This notebook took {:0.2f} minutes to run\".format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "* Explore yellowbrick/charts further\n",
    "* Refine plots\n",
    "* Duplicate for casual riders\n",
    "* Try neg-MSE as scoring method?\n",
    "  * May be a better fit, but harder to interpret since it's relative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
